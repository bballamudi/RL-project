{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value iteration on gridworld\n",
    "This notebook shows how to use value iteration on the gridworld environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set relative path to parent directory\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import and set up environment\n",
    "from environments.gridWorld import gridWorld\n",
    "env = gridWorld()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value iteration algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "def value_iteration(mdp, epsilon, gamma):\n",
    "    V = dict()\n",
    "    # Initialize utilities to zero\n",
    "    for s in env.states():\n",
    "        V.update({s: 0.0})\n",
    "    while(True):\n",
    "        V_prev = copy.deepcopy(V)\n",
    "        delta = 0\n",
    "        for s in mdp.states():\n",
    "            lst = []\n",
    "            for a in mdp.actions(s):\n",
    "                value_sum = 0\n",
    "                for s_next in mdp.states():\n",
    "                    value_sum += mdp.transition_probability(s_next, s, a)*V_prev[s_next]\n",
    "                lst.append(value_sum)\n",
    "            V[s] = mdp.reward(s) + (0 if (lst == []) else gamma*np.max(lst))\n",
    "            if np.abs(V[s] - V_prev[s]) > delta:\n",
    "                delta = np.abs(V[s] - V_prev[s])\n",
    "        #print(delta)\n",
    "        if delta < epsilon*(1 - gamma)/gamma or (gamma == 1 and delta  < epsilon):\n",
    "            return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the policy given the value function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def policy(mdp, V):\n",
    "    PI = dict()\n",
    "    for s in mdp.states():\n",
    "        a_lst = []\n",
    "        v_lst = []\n",
    "        for a in mdp.actions(s):\n",
    "            value_sum = 0\n",
    "            for s_next in mdp.states():\n",
    "                value_sum += mdp.transition_probability(s_next, s, a)*V[s_next]\n",
    "            v_lst.append(value_sum)\n",
    "            a_lst.append(a)\n",
    "        if len(a_lst) > 0:\n",
    "            PI.update({s: a_lst[np.argmax(v_lst)]})\n",
    "    return PI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling the function\n",
    "We now call the value itteration function and the policy finding function and visualize optimal the value function and policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.812\t0.868\t0.918\t1.000\t\n",
      "0.762\tx\t0.660\t-1.000\t\n",
      "0.705\t0.655\t0.611\t0.387\t\n"
     ]
    }
   ],
   "source": [
    "V = value_iteration(env, 1e-3, 1)\n",
    "\n",
    "for y in range(env.board_mask.shape[0]):\n",
    "    for x in range(env.board_mask.shape[1]):\n",
    "        try:\n",
    "            print('{0:.3f}'.format(V[(y, x)]), end='\\t')\n",
    "        except:\n",
    "            print('x', end='\\t')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R\tR\tR\tx\t\n",
      "U\tx\tU\tx\t\n",
      "U\tL\tL\tL\t\n"
     ]
    }
   ],
   "source": [
    "P = policy(env, V)\n",
    "\n",
    "for y in range(env.board_mask.shape[0]):\n",
    "    for x in range(env.board_mask.shape[1]):\n",
    "        try:\n",
    "            print(P[(y, x)], end = '\\t')\n",
    "        except:\n",
    "            print('x', end='\\t')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
